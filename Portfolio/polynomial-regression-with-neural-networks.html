<!DOCTYPE HTML>

<html lang='en-gb' >

    <body class="is-preload">
        <head>
        <link rel="stylesheet" href="assets/css/main.css" />
        <link href="assets/css/prism.css" rel="stylesheet" />
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <meta name="description" content="Learning Tensorflow/Keras for Python by using a neural network for polynomial regression" />
        <title>Learning Nerual networks with Keras and polynomial regression</title>
        </head>
        <nav id="nav">
            <ul class="container">
                <li><a href="index.html">Home</a></li>
            </ul>
        </nav>

        <article class="wrapper style3">
            
        <h1>Learning TensorFlow/Keras by polynomial regression</h1>
        <div class="center">
            <p><b>
                This is my attempt the learn artificial neural networks (ANNs) by breaking them down
           into there constituent parts and running as simple code as possible. <br> <a href="linear-regression-with-neural-networks-2020.html">Previously</a>, I looked at linear regression
           and how a neural network could be used to fit the data. This is an extension of that with more complicated data.
           </b></p>
        

           <p>
            Firstly, I need to create some data. For this I used the <a href="draw-and-save-your-data.html">DataCreator</a> app, so that I could shape data.
           </p>
        </div>
        <span class="image"><img src="images/polydata.png" alt="" /></span>

        <div class="center">
           <p>
               Just as before I will fit the data using the tried and tested methods first. Here I will use Numpy's polyfit function to fit the data.
               From memory, I recognise this shape as a third order polynomial, meaning that it has the form ax<sup>3</sup> + bx<sup>2</sup> + cx + d.
               If I had forgotten this I would have simply brute-forced it and incremented the order in the polyfit function untill I could see that the model fit!
           </p>
        </div>

        <div class="container">
            <pre>
            <code class='language-python'>
                p = np.poly1d(np.polyfit(X,y,3))
                t = np.linspace(0, 1, len(X))
                plt.plot(X, y, 'o', t, p(t), '-');
            </code>
            </pre>
        </div>

        <span class="image"><img src="images/np-polyfit.png" alt="" /></span> 
    <div class="center">

        <p>Looks good! We can see how many parameters were used to fit the model. As it is a third order polynomial we know that we need four parameters</p>
        
    </div>
    <div class="container">
        <pre>
        <code class='language-python'>
            poly1d([-5.23430684,  8.19136844, -2.25798128,  0.17015533])
        </code>
        </pre>
    </div>
        <p>
            Now, for fun, we can try and let tensorflow learn what these parameters should be by trial and error.
        </p>
        <div class="container">
            <pre>
            <code class='language-python'>
                def build_model():             
                    activation = 'linear'
                    
                    input_layer = Input([1])
                    x_cubed = Lambda(lambda x:np.power(x,3))(input_layer)
                    x_squared = Lambda(lambda x:np.power(x,2))(input_layer)
                    hidden = Concatenate()([x_cubed,x_squared,input_layer])
                    output = Dense(1, activation = activation)(hidden)
                    
                    model = Model(inputs=input_layer, outputs=output)

                    return model

                    def scheduler(epoch):
                        if epoch > 500:
                            return 0.1
                        elif epoch > 1000:
                            return 0.01
                        else:
                            return 0.5

                    callback = tf.keras.callbacks.LearningRateScheduler(scheduler)

                    optimizer = Adam()
                    model = build_model()
                    model.compile(loss='mean_squared_error',optimizer=optimizer)
                    history = model.fit(X,y,epochs=2000, verbose=2, callbacks=[callback])
            </code>
            </pre>
        </div>
        
        <span class="image"><img src="images/poly_mod_summary_500.png" alt="" /></span> 
        <div class="center">
            <br>
            <p>
            Here we are making use of the Lambda functions that allow us to make our own functions for use in the network. Because we know we need four parameters
            to fit the data the output from the network is a concatenation layer with four parameters in the form of a third order polynomial.
            </p>
         </div>
        

        <span class="image"><img src="images/final-fig-poly.png" alt="" /></span> 

        <div class="center">
            <br>
            <p>
                Success! The model was able to optimise the parameters and fit the data. Essentially all we have done is used Keras to make use of the 
                <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">Adam</a> optimiser to fit our parameters. 
                Obviously this was a much more inefficient solution to this problem than using the numpy poly1d function, but I am trying to learn the 
                fundamentals of neural networks and machine learning and this exercise was a stepping stone.
            </p>
            <p>
                The next step, for me, is to implement an optimisation algorithm on some basic data.    
            </p>
         </div>

         <div class="container">
            <pre>
            <code class='language-python'>
                #packages used
                import tensorflow as tf
                import numpy as np
                import matplotlib.pyplot as plt
                import keras
                from keras.models import Sequential, Model
                from keras.layers import Dense, Input
                from keras.optimizers import Adam
                from keras.layers import Lambda, Concatenate
                from scipy import stats
                from sklearn.preprocessing import MinMaxScaler
            </code>
            </pre>
        </div>

        </article>

        <div class="col-12-small">
            <hr />
            <h3>Find me on ...</h3>
            <ul class="social" id = "contact">
                <li><a href="https://twitter.com/JLJ_1" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
                <li><a href="https://www.linkedin.com/in/jljasper" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
                <li><a href="https://github.com/Jake-Jasper" class="icon brands fa-github"><span class="label">Github</span></a></li>
            </ul>
            <hr />
        </div>
       






        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        <script src="assets/js/prism.js"></script>
    </body>

</html>

